{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to demonstrate the performance of AlphaTims.\n",
    "It contains the following information:\n",
    "1. [**Samples**](#Samples)\n",
    "2. [**Reading raw Bruker .d folders**](#Reading-raw-Bruker-.d-folders)\n",
    "3. [**Saving HDF files**](#Saving-HDF-files)\n",
    "4. [**Reading HDF files**](#Reading-HDF-files)\n",
    "5. [**Slicing data**](#Slicing-data)\n",
    "6. [**Final overview**](#Final-overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following system was used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:09:02.800526Z",
     "iopub.status.busy": "2021-05-18T19:09:02.799519Z",
     "iopub.status.idle": "2021-05-18T19:09:03.059022Z",
     "shell.execute_reply": "2021-05-18T19:09:03.058064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-11 18:20:49> Platform information:\n",
      "2021-06-11 18:20:49> system        - Darwin\n",
      "2021-06-11 18:20:49> release       - 19.6.0\n",
      "2021-06-11 18:20:49> version       - 10.15.7\n",
      "2021-06-11 18:20:49> machine       - x86_64\n",
      "2021-06-11 18:20:49> processor     - i386\n",
      "2021-06-11 18:20:49> cpu count     - 8\n",
      "2021-06-11 18:20:49> cpu frequency - 2300.00 Mhz\n",
      "2021-06-11 18:20:49> ram           - 24.5/32.0 Gb (available/total)\n",
      "2021-06-11 18:20:49> \n",
      "2021-06-11 18:20:49> Python information:\n",
      "2021-06-11 18:20:49> alphatims  - 0.2.8\n",
      "2021-06-11 18:20:49> bokeh      - 2.2.3\n",
      "2021-06-11 18:20:49> click      - 8.0.1\n",
      "2021-06-11 18:20:49> datashader - 0.12.1\n",
      "2021-06-11 18:20:49> h5py       - 3.2.1\n",
      "2021-06-11 18:20:49> hvplot     - 0.7.1\n",
      "2021-06-11 18:20:49> numba      - 0.53.1\n",
      "2021-06-11 18:20:49> pandas     - 1.2.4\n",
      "2021-06-11 18:20:49> psutil     - 5.8.0\n",
      "2021-06-11 18:20:49> python     - 3.8.10\n",
      "2021-06-11 18:20:49> python-lzf - 0.2.4\n",
      "2021-06-11 18:20:49> pyzstd     - 0.15.0\n",
      "2021-06-11 18:20:49> selenium   - 3.141.0\n",
      "2021-06-11 18:20:49> tqdm       - 4.60.0\n",
      "2021-06-11 18:20:49> \n"
     ]
    }
   ],
   "source": [
    "import alphatims.utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alphatims.utils.set_threads(8)\n",
    "log_file_name = alphatims.utils.set_logger(\n",
    "    log_file_name=\"performance_log.txt\",\n",
    "    overwrite=True\n",
    ")\n",
    "alphatims.utils.show_platform_info()\n",
    "alphatims.utils.show_python_info()\n",
    "alphatims.utils.set_progress_callback(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Six samples (https://www.ebi.ac.uk/pride/archive/projects/PXD027359) are used and compared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:09:03.065164Z",
     "iopub.status.busy": "2021-05-18T19:09:03.064525Z",
     "iopub.status.idle": "2021-05-18T19:09:03.066235Z",
     "shell.execute_reply": "2021-05-18T19:09:03.066588Z"
    }
   },
   "outputs": [],
   "source": [
    "file_names = {\n",
    "    \"DDA_6\": \"/Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_MA_HeLa_50ng_5_6min_DDA_S1-B1_1_25185.d\",\n",
    "    \"DIA_6\": \"/Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_SA_HeLa_50ng_5_6min_DIA_high_speed_S1-B2_1_25186.d\",\n",
    "    \"DDA_21\": \"/Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_DDA_21min_8cm_S1-C10_1_22476.d\",\n",
    "    \"DIA_21\": \"/Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_high_speed_21min_8cm_S1-C8_1_22474.d\",\n",
    "    \"DDA_120\": \"/Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_MA_HeLa_400ng_ddaAPSEF_A1_1_7545.d\",\n",
    "    \"DIA_120\": \"/Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_SA_HeLa_400ng_diaPASEF_high_speed_A1_1_7546.d\",\n",
    "}\n",
    "overview = pd.DataFrame(index=file_names.keys())\n",
    "overview[\"Type\"] = pd.Series({x: x.split(\"_\")[0] for x in file_names})\n",
    "overview[\"Gradient (min)\"] = pd.Series({x: x.split(\"_\")[1] for x in file_names})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load all these files to show their basic statistics before we do the actual timing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:09:03.070527Z",
     "iopub.status.busy": "2021-05-18T19:09:03.069971Z",
     "iopub.status.idle": "2021-05-18T19:09:46.437508Z",
     "shell.execute_reply": "2021-05-18T19:09:46.437849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-11 18:20:50> WARNING: No Bruker libraries are available for this operating system. Intensities are uncalibrated, resulting in (very) small differences. However, mobility and m/z values need to be estimated. While this estimation often returns acceptable results with errors < 0.02 Th, huge errors (e.g. offsets of 6 Th) have already been observed for some samples!\n",
      "2021-06-11 18:20:50> \n",
      "2021-06-11 18:20:50> Initial loading of DDA_6\n",
      "2021-06-11 18:20:50> Importing data from /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_MA_HeLa_50ng_5_6min_DDA_S1-B1_1_25185.d\n",
      "2021-06-11 18:20:50> Reading frame metadata for /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_MA_HeLa_50ng_5_6min_DDA_S1-B1_1_25185.d\n",
      "2021-06-11 18:20:51> Reading 3,156 frames with 143,542,808 detector strikes for /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_MA_HeLa_50ng_5_6min_DDA_S1-B1_1_25185.d\n",
      "2021-06-11 18:20:51> Indexing /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_MA_HeLa_50ng_5_6min_DDA_S1-B1_1_25185.d...\n",
      "2021-06-11 18:20:52> Succesfully imported data from /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_MA_HeLa_50ng_5_6min_DDA_S1-B1_1_25185.d\n",
      "2021-06-11 18:20:52> \n",
      "2021-06-11 18:20:52> Initial loading of DIA_6\n",
      "2021-06-11 18:20:52> Importing data from /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_SA_HeLa_50ng_5_6min_DIA_high_speed_S1-B2_1_25186.d\n",
      "2021-06-11 18:20:52> Reading frame metadata for /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_SA_HeLa_50ng_5_6min_DIA_high_speed_S1-B2_1_25186.d\n",
      "2021-06-11 18:20:52> Reading 3,176 frames with 126,982,956 detector strikes for /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_SA_HeLa_50ng_5_6min_DIA_high_speed_S1-B2_1_25186.d\n",
      "2021-06-11 18:20:52> Indexing /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_SA_HeLa_50ng_5_6min_DIA_high_speed_S1-B2_1_25186.d...\n",
      "2021-06-11 18:20:53> Succesfully imported data from /Users/swillems/Data/alphatims_testing/20210510_TIMS03_EVO03_PaSk_SA_HeLa_50ng_5_6min_DIA_high_speed_S1-B2_1_25186.d\n",
      "2021-06-11 18:20:53> \n",
      "2021-06-11 18:20:53> Initial loading of DDA_21\n",
      "2021-06-11 18:20:53> Importing data from /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_DDA_21min_8cm_S1-C10_1_22476.d\n",
      "2021-06-11 18:20:53> Reading frame metadata for /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_DDA_21min_8cm_S1-C10_1_22476.d\n",
      "2021-06-11 18:20:53> Reading 11,886 frames with 295,251,252 detector strikes for /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_DDA_21min_8cm_S1-C10_1_22476.d\n",
      "2021-06-11 18:20:56> Indexing /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_DDA_21min_8cm_S1-C10_1_22476.d...\n",
      "2021-06-11 18:20:56> Succesfully imported data from /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_DDA_21min_8cm_S1-C10_1_22476.d\n",
      "2021-06-11 18:20:56> \n",
      "2021-06-11 18:20:56> Initial loading of DIA_21\n",
      "2021-06-11 18:20:56> Importing data from /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_high_speed_21min_8cm_S1-C8_1_22474.d\n",
      "2021-06-11 18:20:56> Reading frame metadata for /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_high_speed_21min_8cm_S1-C8_1_22474.d\n",
      "2021-06-11 18:20:56> Reading 11,868 frames with 730,564,765 detector strikes for /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_high_speed_21min_8cm_S1-C8_1_22474.d\n",
      "2021-06-11 18:21:00> Indexing /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_high_speed_21min_8cm_S1-C8_1_22474.d...\n",
      "2021-06-11 18:21:01> Succesfully imported data from /Users/swillems/Data/alphatims_testing/20201207_tims03_Evo03_PS_SA_HeLa_200ng_EvoSep_prot_high_speed_21min_8cm_S1-C8_1_22474.d\n",
      "2021-06-11 18:21:01> \n",
      "2021-06-11 18:21:01> Initial loading of DDA_120\n",
      "2021-06-11 18:21:01> Importing data from /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_MA_HeLa_400ng_ddaAPSEF_A1_1_7545.d\n",
      "2021-06-11 18:21:01> Reading frame metadata for /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_MA_HeLa_400ng_ddaAPSEF_A1_1_7545.d\n",
      "2021-06-11 18:21:05> Reading 67,024 frames with 2,736,188,777 detector strikes for /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_MA_HeLa_400ng_ddaAPSEF_A1_1_7545.d\n",
      "2021-06-11 18:21:32> Indexing /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_MA_HeLa_400ng_ddaAPSEF_A1_1_7545.d...\n",
      "2021-06-11 18:21:40> Succesfully imported data from /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_MA_HeLa_400ng_ddaAPSEF_A1_1_7545.d\n",
      "2021-06-11 18:21:40> \n",
      "2021-06-11 18:21:40> Initial loading of DIA_120\n",
      "2021-06-11 18:21:40> Importing data from /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_SA_HeLa_400ng_diaPASEF_high_speed_A1_1_7546.d\n",
      "2021-06-11 18:21:40> Reading frame metadata for /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_SA_HeLa_400ng_diaPASEF_high_speed_A1_1_7546.d\n",
      "2021-06-11 18:21:41> Reading 66,775 frames with 6,364,599,982 detector strikes for /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_SA_HeLa_400ng_diaPASEF_high_speed_A1_1_7546.d\n",
      "2021-06-11 18:22:53> Indexing /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_SA_HeLa_400ng_diaPASEF_high_speed_A1_1_7546.d...\n",
      "2021-06-11 18:23:45> Succesfully imported data from /Users/swillems/Data/alphatims_testing/20210507_TIMS01_LC01_PaSk_SA_HeLa_400ng_diaPASEF_high_speed_A1_1_7546.d\n",
      "2021-06-11 18:23:45> \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import alphatims.bruker\n",
    "\n",
    "timstof_objects = {}\n",
    "detector_events = {}\n",
    "for sample_id, file_name in file_names.items():\n",
    "    logging.info(f\"Initial loading of {sample_id}\")\n",
    "    timstof_objects[sample_id] = alphatims.bruker.TimsTOF(file_name)\n",
    "    detector_events[sample_id] = len(timstof_objects[sample_id])\n",
    "    logging.info(\"\")\n",
    "overview[\"Detector events\"] = pd.Series(detector_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we thus consider the following samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:09:46.452533Z",
     "iopub.status.busy": "2021-05-18T19:09:46.451988Z",
     "iopub.status.idle": "2021-05-18T19:09:46.460529Z",
     "shell.execute_reply": "2021-05-18T19:09:46.460921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_fbc96_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Type</th>        <th class=\"col_heading level0 col1\" >Gradient (min)</th>        <th class=\"col_heading level0 col2\" >Detector events</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_fbc96_level0_row0\" class=\"row_heading level0 row0\" >DDA_6</th>\n",
       "                        <td id=\"T_fbc96_row0_col0\" class=\"data row0 col0\" >DDA</td>\n",
       "                        <td id=\"T_fbc96_row0_col1\" class=\"data row0 col1\" >6</td>\n",
       "                        <td id=\"T_fbc96_row0_col2\" class=\"data row0 col2\" >143,542,808</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbc96_level0_row1\" class=\"row_heading level0 row1\" >DIA_6</th>\n",
       "                        <td id=\"T_fbc96_row1_col0\" class=\"data row1 col0\" >DIA</td>\n",
       "                        <td id=\"T_fbc96_row1_col1\" class=\"data row1 col1\" >6</td>\n",
       "                        <td id=\"T_fbc96_row1_col2\" class=\"data row1 col2\" >126,982,956</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbc96_level0_row2\" class=\"row_heading level0 row2\" >DDA_21</th>\n",
       "                        <td id=\"T_fbc96_row2_col0\" class=\"data row2 col0\" >DDA</td>\n",
       "                        <td id=\"T_fbc96_row2_col1\" class=\"data row2 col1\" >21</td>\n",
       "                        <td id=\"T_fbc96_row2_col2\" class=\"data row2 col2\" >295,251,252</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbc96_level0_row3\" class=\"row_heading level0 row3\" >DIA_21</th>\n",
       "                        <td id=\"T_fbc96_row3_col0\" class=\"data row3 col0\" >DIA</td>\n",
       "                        <td id=\"T_fbc96_row3_col1\" class=\"data row3 col1\" >21</td>\n",
       "                        <td id=\"T_fbc96_row3_col2\" class=\"data row3 col2\" >730,564,765</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbc96_level0_row4\" class=\"row_heading level0 row4\" >DDA_120</th>\n",
       "                        <td id=\"T_fbc96_row4_col0\" class=\"data row4 col0\" >DDA</td>\n",
       "                        <td id=\"T_fbc96_row4_col1\" class=\"data row4 col1\" >120</td>\n",
       "                        <td id=\"T_fbc96_row4_col2\" class=\"data row4 col2\" >2,736,188,777</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbc96_level0_row5\" class=\"row_heading level0 row5\" >DIA_120</th>\n",
       "                        <td id=\"T_fbc96_row5_col0\" class=\"data row5 col0\" >DIA</td>\n",
       "                        <td id=\"T_fbc96_row5_col1\" class=\"data row5 col1\" >120</td>\n",
       "                        <td id=\"T_fbc96_row5_col2\" class=\"data row5 col2\" >6,364,599,982</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa270be9bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.style.format({\"Detector events\": \"{:,}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading raw Bruker .d folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid unwanted system inferences, we perform a `timeit` function to get a robust estimate of loading times for raw Bruker .d folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:09:46.465819Z",
     "iopub.status.busy": "2021-05-18T19:09:46.465290Z",
     "iopub.status.idle": "2021-05-18T19:14:18.440686Z",
     "shell.execute_reply": "2021-05-18T19:14:18.441256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load DDA_6 raw Bruker .d folder:\n",
      "1.16 s ± 86 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DIA_6 raw Bruker .d folder:\n",
      "921 ms ± 42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DDA_21 raw Bruker .d folder:\n",
      "3 s ± 40.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DIA_21 raw Bruker .d folder:\n",
      "4.71 s ± 33.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DDA_120 raw Bruker .d folder:\n",
      "31.2 s ± 2.06 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DIA_120 raw Bruker .d folder:\n",
      "1min 27s ± 2.59 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alphatims.utils.set_logger(stream=False)\n",
    "raw_load_times = {}\n",
    "for sample_id, file_name in file_names.items():\n",
    "    print(f\"Time to load {sample_id} raw Bruker .d folder:\")\n",
    "    raw_load_time = %timeit -o tmp = alphatims.bruker.TimsTOF(file_name)\n",
    "    raw_load_times[sample_id] = np.average(raw_load_time.timings)\n",
    "    print(\"\")\n",
    "overview[\"Load .d (s)\"] = pd.Series(raw_load_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving HDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the data files can also be exported to HDF files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:14:18.460206Z",
     "iopub.status.busy": "2021-05-18T19:14:18.459593Z",
     "iopub.status.idle": "2021-05-18T19:16:55.941689Z",
     "shell.execute_reply": "2021-05-18T19:16:55.942748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to export DDA_6 to HDF file:\n",
      "409 ms ± 82.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to export DIA_6 to HDF file:\n",
      "338 ms ± 31.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to export DDA_21 to HDF file:\n",
      "798 ms ± 43.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to export DIA_21 to HDF file:\n",
      "1.92 s ± 224 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to export DDA_120 to HDF file:\n",
      "6.92 s ± 290 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to export DIA_120 to HDF file:\n",
      "3min 58s ± 7.3 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_hdf_times = {}\n",
    "for sample_id, data in timstof_objects.items():\n",
    "    print(f\"Time to export {sample_id} to HDF file:\")\n",
    "    path = data.directory\n",
    "    file_name = f\"{data.sample_name}.hdf\"\n",
    "    save_hdf_time = %timeit -o tmp = data.save_as_hdf(path, file_name, overwrite=True)\n",
    "    save_hdf_times[sample_id] = np.average(save_hdf_time.timings)\n",
    "    print(\"\")\n",
    "overview[\"Save .hdf (s)\"] = pd.Series(save_hdf_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading HDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once these HDF files are created, they can be loaded much faster than raw Bruker .d folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:16:55.963880Z",
     "iopub.status.busy": "2021-05-18T19:16:55.962853Z",
     "iopub.status.idle": "2021-05-18T19:19:11.772987Z",
     "shell.execute_reply": "2021-05-18T19:19:11.773541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load DDA_6 HDF file:\n",
      "403 ms ± 42.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DIA_6 HDF file:\n",
      "157 ms ± 8.73 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DDA_21 HDF file:\n",
      "913 ms ± 76.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DIA_21 HDF file:\n",
      "2.54 s ± 305 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DDA_120 HDF file:\n",
      "13.8 s ± 377 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Time to load DIA_120 HDF file:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "load_hdf_times = {}\n",
    "for sample_id, data in timstof_objects.items():\n",
    "    print(f\"Time to load {sample_id} HDF file:\")\n",
    "    file_name = os.path.join(data.directory, f\"{data.sample_name}.hdf\")\n",
    "    load_hdf_time = %timeit -o tmp = alphatims.bruker.TimsTOF(file_name)\n",
    "    load_hdf_times[sample_id] = np.average(load_hdf_time.timings)\n",
    "    print(\"\")\n",
    "overview[\"Load .hdf (s)\"] = pd.Series(load_hdf_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can slice this data. Since this uses Numba JIT compilation, we first compile the relevant functions with an initial slice call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:19:11.825925Z",
     "iopub.status.busy": "2021-05-18T19:19:11.789664Z",
     "iopub.status.idle": "2021-05-18T19:19:11.827183Z",
     "shell.execute_reply": "2021-05-18T19:19:11.826604Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = timstof_objects[\"DDA_6\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can time how long it takes to slice in different dimensions:\n",
    "   * **LC:** $100.0 \\leq \\textrm{retention_time} \\lt 100.5$\n",
    "   * **TIMS:** $\\textrm{scan_index} = 450$\n",
    "   * **Quadrupole:** $700.0 \\leq \\textrm{quad_mz_values} \\lt 710.0$\n",
    "   * **TOF:** $621.9 \\leq \\textrm{tof_mz_values} \\lt 622.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T19:19:11.853198Z",
     "iopub.status.busy": "2021-05-18T19:19:11.850931Z",
     "iopub.status.idle": "2021-05-18T19:22:43.575327Z",
     "shell.execute_reply": "2021-05-18T19:22:43.575658Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "frame_slice_times = {}\n",
    "scan_slice_times = {}\n",
    "quad_slice_times = {}\n",
    "tof_slice_times = {}\n",
    "\n",
    "frame_slice_counts = {}\n",
    "scan_slice_counts = {}\n",
    "quad_slice_counts = {}\n",
    "tof_slice_counts = {}\n",
    "\n",
    "for sample_id, data in timstof_objects.items():\n",
    "    print(f\"Time to slice {sample_id}:\")\n",
    "    \n",
    "    count = len(data[100.:100.5, \"raw\"])\n",
    "    print(\n",
    "        f\"Testing LC slice data[100.0: 100.5] ({count:,} detector hits).\"\n",
    "    )\n",
    "    frame_slice_time = %timeit -o tmp = data[100.:100.5, \"raw\"]\n",
    "    frame_slice_counts[sample_id] = count\n",
    "    frame_slice_times[sample_id] = np.average(frame_slice_time.timings)\n",
    "    \n",
    "    count = len(data[:, 450, \"raw\"])\n",
    "    print(\n",
    "        f\"Testing TIMS slice data[:, 450] ({count:,} detector hits).\"\n",
    "    )\n",
    "    scan_slice_time = %timeit -o tmp = data[:, 450, \"raw\"]\n",
    "    scan_slice_counts[sample_id] = count\n",
    "    scan_slice_times[sample_id] = np.average(scan_slice_time.timings)\n",
    "    \n",
    "    count = len(data[:, :, 700.0: 710, \"raw\"])\n",
    "    print(\n",
    "        f\"Testing QUAD slice data[:, :, 700.0: 710] ({count:,} detector hits).\"\n",
    "    )\n",
    "    quad_slice_time = %timeit -o tmp = data[:, :, 700.0: 710, \"raw\"]\n",
    "    quad_slice_counts[sample_id] = count\n",
    "    quad_slice_times[sample_id] = np.average(quad_slice_time.timings)\n",
    "    \n",
    "    count = len(data[:, :, :, 621.9: 622.1, \"raw\"])\n",
    "    print(\n",
    "        f\"Testing TOF slice data[:, :, :, 621.9: 622.1] ({count:,} detector hits).\"\n",
    "    )\n",
    "    tof_slice_time = %timeit -o tmp = data[:, :, :, 621.9: 622.1, \"raw\"]\n",
    "    tof_slice_counts[sample_id] = count\n",
    "    tof_slice_times[sample_id] = np.average(tof_slice_time.timings)\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "overview[\"Slice LC (s)\"] = pd.Series(frame_slice_times)\n",
    "overview[\"Slice LC (hits)\"] = pd.Series(frame_slice_counts)\n",
    "overview[\"Slice TIMS (s)\"] = pd.Series(scan_slice_times)\n",
    "overview[\"Slice TIMS (hits)\"] = pd.Series(scan_slice_counts)\n",
    "overview[\"Slice QUAD (s)\"] = pd.Series(quad_slice_times)\n",
    "overview[\"Slice QUAD (hits)\"] = pd.Series(quad_slice_counts)\n",
    "overview[\"Slice TOF (s)\"] = pd.Series(tof_slice_times)\n",
    "overview[\"Slice TOF (hits)\"] = pd.Series(tof_slice_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final time performance can thus be summarized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(overview):\n",
    "    new_overview = pd.DataFrame()\n",
    "    for column_name, dtype in zip(overview.columns, overview.dtypes):\n",
    "        new_column = overview[column_name]\n",
    "        if dtype == np.int64:\n",
    "            new_column = new_column.apply(lambda z: f\"{z:,}\")\n",
    "        elif dtype == np.float64:\n",
    "            new_column = new_column.apply(lambda z: f\"{z:#.3g}\")\n",
    "        new_overview[column_name] = new_column\n",
    "    return new_overview.T\n",
    "\n",
    "overview.T.to_csv(\"performance_results.csv\")\n",
    "format_df(overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, it can be presented visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "sizes = np.sqrt(overview[\"Detector events\"]/10**5)\n",
    "edgecolors = [\"black\" for i in overview[\"Type\"].values]\n",
    "linestyle = [\":\" if i == \"DIA\" else \"-\" for i in overview[\"Type\"].values]\n",
    "scatter_dimensions = [\n",
    "    (overview[\"Detector events\"], overview[\"Load .d (s)\"]),\n",
    "    (overview[\"Detector events\"], overview[\"Load .hdf (s)\"]),\n",
    "    (overview[\"Detector events\"], overview[\"Save .hdf (s)\"]),\n",
    "    (overview[\"Slice LC (hits)\"], overview[\"Slice LC (s)\"]),\n",
    "    (overview[\"Slice TIMS (hits)\"], overview[\"Slice TIMS (s)\"]),\n",
    "    (overview[\"Slice QUAD (hits)\"], overview[\"Slice QUAD (s)\"]),\n",
    "    (overview[\"Slice TOF (hits)\"], overview[\"Slice TOF (s)\"]),\n",
    "]\n",
    "\n",
    "for x, y in scatter_dimensions:\n",
    "    plt.scatter(x, y, alpha=0.50, s=sizes, edgecolors=\"black\", linestyle=linestyle)\n",
    "    \n",
    "function_legend = plt.legend(\n",
    "    labels=[\n",
    "        \"Load .d\",\n",
    "        \"Load .hdf\",\n",
    "        \"Save .hdf\",\n",
    "        \"Slice LC\",\n",
    "        \"Slice TIMS\",\n",
    "        \"Slice quadrupole\",\n",
    "        \"Slice TOF\",\n",
    "    ],\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(1, 0),\n",
    "    scatterpoints=1,\n",
    "    frameon=False,\n",
    ")\n",
    "for i, sc in enumerate(scatter_dimensions):\n",
    "    function_legend.legendHandles[i].set_edgecolor(None)\n",
    "    \n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "sample_legend = plt.legend(\n",
    "    [ \n",
    "        f\"{acq} {grad} min\" for acq, grad in zip(\n",
    "            overview[\"Type\"],\n",
    "            overview[\"Gradient (min)\"]\n",
    "        )\n",
    "    ],\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    scatterpoints=1,\n",
    "    frameon=False,\n",
    ")\n",
    "for i, size in enumerate(sizes):\n",
    "    sample_legend.legendHandles[i]._sizes = [size]\n",
    "    sample_legend.legendHandles[i].set_color('grey')\n",
    "    sample_legend.legendHandles[i].set_linestyle(linestyle[i])\n",
    "    sample_legend.legendHandles[i].set_edgecolor('black')\n",
    "    \n",
    "plt.gca().add_artist(sample_legend)\n",
    "plt.gca().add_artist(function_legend)\n",
    "\n",
    "plt.xlabel(\"#Detector events (logscale)\")\n",
    "plt.ylabel(\"Time in seconds (logscale)\")\n",
    "plt.savefig(\n",
    "    'performance_results.pdf',\n",
    "    format='pdf',\n",
    "    dpi=1200,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.savefig(\n",
    "    'performance_results.png',\n",
    "    format='png',\n",
    "    dpi=1200,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alphatims]",
   "language": "python",
   "name": "conda-env-alphatims-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
